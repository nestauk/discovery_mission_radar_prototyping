{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discovery_utils.getters import gtr\n",
    "from discovery_utils.getters import crunchbase\n",
    "from discovery_utils.utils import search\n",
    "from discovery_utils.utils.llm.batch_check import LLMProcessor, generate_system_message\n",
    "from discovery_utils.utils import viz_landscape, analysis_crunchbase\n",
    "from discovery_utils.utils.analysis_crunchbase import get_timeseries\n",
    "from discovery_utils.utils import charts\n",
    "from discovery_utils.utils import analysis\n",
    "\n",
    "import asyncio\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from src import PROJECT_DIR\n",
    "from src import VECTOR_DB_DIR\n",
    "\n",
    "OUTPUT_DIR = PROJECT_DIR / 'data/2025_01_MS_ahl/'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SCORE_THRESHOLD = 0.3\n",
    "\n",
    "CONFIGS = [\n",
    "    \"challenger_brands\",\n",
    "    \"child_obesity\",\n",
    "    \"food_as_medicine\",\n",
    "    \"future_of_ag\",\n",
    "    \"glp1\",\n",
    "    \"hormonal_dysregulation\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "investment_types = [\"angel\", \"pre_seed\", \"seed\", \"series_a\", \"series_b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CB = crunchbase.CrunchbaseGetter(vector_db_path=VECTOR_DB_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ipos_df = []\n",
    "all_acquisitions_df = []\n",
    "all_growth_rates = []\n",
    "all_export_df = []\n",
    "\n",
    "for config_name in CONFIGS:\n",
    "    \n",
    "    config_filename = f\"config_MS_{config_name}.yaml\"\n",
    "    print(f\"Processing {config_filename}\")\n",
    "    # Search the database with keywords and vectors\n",
    "    SearchCB = search.SearchDataset(CB, CB.organisations_enriched, config_filename)\n",
    "    search_cb_df = (\n",
    "        SearchCB.do_search()\n",
    "        # add full description text\n",
    "        .merge(CB.descriptions[['id', 'description']], on='id', how='left')\n",
    "        .fillna({'description': '', 'short_description': '', 'name': ''})\n",
    "        .assign(text = lambda df: df['name'] + '. ' + df['short_description'] + ' ' + df['description'])\n",
    "    )    \n",
    "\n",
    "    # Filter the results to only include those with a score above a threshold\n",
    "    relevant_df = search_cb_df.query(f\"_score_avg > {SCORE_THRESHOLD}\")\n",
    "\n",
    "    system_message = generate_system_message(config_filename)\n",
    "    fields = [\n",
    "        {\"name\": \"is_relevant\", \"type\": \"str\", \"description\": \"A one-word answer: 'yes' or 'no'.\"},\n",
    "    ]\n",
    "    check_data = dict(zip(relevant_df['id'], relevant_df['text']))\n",
    "\n",
    "    processor = LLMProcessor(\n",
    "        output_path=str(OUTPUT_DIR / f\"llm_check_MS_{config_name}.jsonl\"),\n",
    "        system_message=system_message,\n",
    "        session_name=\"mission_studio\",\n",
    "        output_fields=fields,\n",
    "    )\n",
    "\n",
    "    await processor.run(check_data, batch_size=15, sleep_time=0.5)   \n",
    "    \n",
    "    relevant_check_df = pd.read_json(OUTPUT_DIR / f\"llm_check_MS_{config_name}.jsonl\", lines=True)\n",
    "    relevant_checked_df = relevant_df.merge(relevant_check_df[['id', 'is_relevant']], left_on='id', right_on='id', how='left')\n",
    "    matching_ids = relevant_checked_df.query(\"is_relevant == 'yes'\").id.tolist()\n",
    "\n",
    "    # IPOs and acquisitions\n",
    "    ipos_df = CB.ipos.query(\"org_id in @matching_ids\")\n",
    "    acquisitions_df = CB.acquisitions.query(\"acquiree_id in @matching_ids\")\n",
    "\n",
    "    if len(ipos_df) > 0:\n",
    "        ipos_df.to_csv(OUTPUT_DIR / f\"ipos_{config_name}.csv\", index=False)\n",
    "        all_ipos_df.append(ipos_df.assign(theme=config_name))\n",
    "\n",
    "    if len(acquisitions_df) > 0:\n",
    "        acquisitions_df.to_csv(OUTPUT_DIR / f\"acquisitions_{config_name}.csv\", index=False)\n",
    "        all_acquisitions_df.append(acquisitions_df.assign(theme=config_name)) \n",
    "\n",
    "    # Time series analysis\n",
    "    ts_df = get_timeseries(\n",
    "        cb_orgs = CB.organisations_enriched.query(\"id in @matching_ids\"),\n",
    "        cb_funding_rounds = CB.funding_rounds_enriched.query(\"org_id in @matching_ids\").drop_duplicates(\"funding_round_id\").query(\"investment_type in @investment_types\"),\n",
    "        min_year = 2010,\n",
    "        max_year = 2025,\n",
    "        period='year',\n",
    "    )\n",
    "    growth_rates = analysis.smoothed_growth(ts_df, year_start=2020, year_end=2024)\n",
    "    growth_rates_df = pd.DataFrame(growth_rates, columns=[config_name]).T.reset_index().rename(columns={'index': 'theme'})\n",
    "    all_growth_rates.append(growth_rates_df)\n",
    "\n",
    "    if len(matching_ids) > 20:            \n",
    "        # Generate the landscapes\n",
    "        id_condition = \"id in ('{}')\".format(\"', '\".join(list(matching_ids)))\n",
    "        vectors_df = CB.VectorDB.vector_db.search().where(id_condition).limit(30000).to_pandas()    \n",
    "\n",
    "        fig, cb_viz_df = viz_landscape.generate_crunchbase_landscape(vectors_df, CB, min_cluster_size=15, n_keyword_clusters=10)\n",
    "\n",
    "        output_path = f\"cb_landscape_{config_name}.html\"\n",
    "        fig.save(str(output_path))    \n",
    "        #cb_viz_df.to_csv(f\"cb_landscape_{config_name}.csv\", index=False)\n",
    "\n",
    "        export_df = (\n",
    "            relevant_checked_df\n",
    "            .merge(cb_viz_df[['id', 'category', 'keyword_cluster', 'recent_funding', 'region']], on='id', how='left')\n",
    "        )   \n",
    "        export_df.to_csv(OUTPUT_DIR / f\"cb_landscape_data_{config_name}.csv\", index=False)\n",
    "        all_export_df.append(export_df.assign(theme=config_name))\n",
    "    else:\n",
    "        print(f\"Not enough companies to generate landscape for {config_name}\")\n",
    "        relevant_checked_df.to_csv(OUTPUT_DIR / f\"cb_landscape_data_{config_name}.csv\", index=False)\n",
    "\n",
    "\n",
    "all_ipos_df = pd.concat(all_ipos_df, ignore_index=True).to_csv(OUTPUT_DIR / \"all_ipos.csv\", index=False)\n",
    "all_acquisitions_df = pd.concat(all_acquisitions_df, ignore_index=True).to_csv(OUTPUT_DIR / \"all_acquisitions.csv\", index=False)\n",
    "\n",
    "all_growth_rates_df = pd.concat(all_growth_rates, ignore_index=True)\n",
    "all_growth_rates_df.to_csv(OUTPUT_DIR / \"growth_rates.csv\", index=False)\n",
    "\n",
    "all_export_df = pd.concat(all_export_df, ignore_index=True)\n",
    "all_export_df.to_csv(OUTPUT_DIR / \"all_cb_landscape_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df = get_timeseries(\n",
    "    cb_orgs = CB.organisations_enriched,\n",
    "    cb_funding_rounds = CB.funding_rounds_enriched.drop_duplicates(\"funding_round_id\").query(\"investment_type in @investment_types\"),\n",
    "    min_year = 2010,\n",
    "    max_year = 2025,\n",
    "    period='year',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_growth_rates = analysis.smoothed_growth(baseline_df, year_start=2020, year_end=2024)\n",
    "baseline_growth_rates = pd.DataFrame(baseline_growth_rates, columns=[\"baseline\"]).T.reset_index().rename(columns={'index': 'baseline'})\n",
    "baseline_growth_rates.to_csv(OUTPUT_DIR / \"baseline_growth_rates.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_growth_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = charts.ts_bar(\n",
    "    ts=baseline_df,\n",
    "    variable = \"raised_amount_gbp_total\",\n",
    "    variable_title = \"Total global investment\"\n",
    ")\n",
    "# save png with altair\n",
    "fig.save(str(OUTPUT_DIR / \"v2_baseline_investment.png\"), scale_factor=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = charts.ts_bar(\n",
    "    ts=baseline_df,\n",
    "    variable = \"n_orgs_founded\",\n",
    "    variable_title = \"Number of organisations founded\"\n",
    ")\n",
    "fig.save(str(OUTPUT_DIR / \"v2_baseline_new_companies.png\"), scale_factor=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funding_rounds_df = CB.funding_rounds_enriched.drop_duplicates(\"funding_round_id\").query(\"investment_type in @investment_types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deals_df, deal_counts_df = analysis_crunchbase.get_funding_by_year_and_range(funding_rounds_df, 2014, 2025)\n",
    "aggregated_funding_types_df = analysis_crunchbase.aggregate_by_funding_round_types(funding_rounds_df.query(\"year >= 2014\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "investment_types_fig = analysis_crunchbase.chart_investment_types(aggregated_funding_types_df)\n",
    "investment_types_fig.save(str(OUTPUT_DIR / \"v2_baseline_investment_types.png\"), scale_factor=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "investment_types_counts_fig = analysis_crunchbase.chart_investment_types_counts(aggregated_funding_types_df)\n",
    "investment_types_counts_fig.save(str(OUTPUT_DIR / \"v2_baseline_investment_types_counts.png\"), scale_factor=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deal_sizes_counts_fig = analysis_crunchbase.chart_deal_sizes_counts(deal_counts_df)\n",
    "deal_sizes_counts_fig.save(str(OUTPUT_DIR / \"v2_baseline_deal_sizes_counts.png\"), scale_factor=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deal_sizes_fig = analysis_crunchbase.chart_deal_sizes(deals_df)\n",
    "deal_sizes_fig.save(str(OUTPUT_DIR / \"v2_baseline_deal_sizes.png\"), scale_factor=2.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discovery-mission-radar-prototyping-ejbE0IFh-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
